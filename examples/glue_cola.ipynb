{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm.auto import trange\n",
    "\n",
    "dd = load_dataset(\"nyu-mll/glue\", \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/micromamba/envs/core/lib/python3.11/site-packages/sae_lens/sae.py:136: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "from probe_lens import ActivationStore, ProbeTrainer\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"gpt2-small\")\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "hook_point = \"blocks.7.hook_resid_pre\"\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\", sae_id=hook_point, device=device\n",
    ")\n",
    "model.add_sae(sae, hook_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dd['train'].features['label'].names\n",
    "\n",
    "def filter_fn(activations):\n",
    "    return activations[:, -1:, :]\n",
    "\n",
    "store = ActivationStore(model, hooks=[sae.hook_sae_acts_post], class_names=labels, act_filter_fn=filter_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a61dd8490a49dcbdb5e1d62bdf2fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = dd['train']\n",
    "store.set_split(\"train\")\n",
    "\n",
    "store.add_labels(ds['label'][:20*64])\n",
    "\n",
    "batch_size = 64\n",
    "prompts_train = ds['sentence'][:20*64]\n",
    "for i in trange(0, len(prompts_train), batch_size):\n",
    "    batch = prompts_train[i : i + batch_size]\n",
    "    model(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b7a920ca3d4882bd9ba0f653fa0a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = dd['validation']\n",
    "store.set_split(\"test\")\n",
    "\n",
    "store.add_labels(ds['label'])\n",
    "\n",
    "batch_size = 64\n",
    "prompts_test = ds['sentence']\n",
    "for i in trange(0, len(prompts_test), batch_size):\n",
    "    batch = prompts_test[i : i + batch_size]\n",
    "    model(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'blocks.7.hook_resid_pre.hook_sae_acts_post'],\n",
       "        num_rows: 1280\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'blocks.7.hook_resid_pre.hook_sae_acts_post'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.detach()\n",
    "act_dd = store.compile_dataset()\n",
    "act_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tom/fun/o1-engineer/linear-probe/ProbeLens/examples/wandb/run-20241004_162038-ryq2ar74</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tompollak/Glue-COLA/runs/ryq2ar74' target=\"_blank\">woven-morning-1</a></strong> to <a href='https://wandb.ai/tompollak/Glue-COLA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tompollak/Glue-COLA' target=\"_blank\">https://wandb.ai/tompollak/Glue-COLA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tompollak/Glue-COLA/runs/ryq2ar74' target=\"_blank\">https://wandb.ai/tompollak/Glue-COLA/runs/ryq2ar74</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c73130c65a146af8ff13d0de7cd8024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training probes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Plotting blocks.7.hook_resid_pre.hook_sae_acts_post.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe Metrics for blocks.7.hook_resid_pre.hook_sae_acts_post:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "unacceptable       0.34      0.07      0.12       322\n",
      "  acceptable       0.69      0.94      0.80       721\n",
      "\n",
      "    accuracy                           0.67      1043\n",
      "   macro avg       0.52      0.51      0.46      1043\n",
      "weighted avg       0.59      0.67      0.59      1043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged feature importances.\n"
     ]
    }
   ],
   "source": [
    "probe_trainer = ProbeTrainer(\n",
    "    act_dd,\n",
    "    flatten_T=\"batch\",\n",
    "    wandb_project=\"Glue-COLA\",\n",
    "    max_iter=1000,\n",
    ")\n",
    "probe_trainer.train()\n",
    "probe_trainer.save_probes(\"./glue_cola_probes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
